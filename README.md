# Отчет о проделанной работе

## Разрез 1. Размер обучающей выборки

### Описание и гипотеза

В этом разрезе исследуется влияние количества обучающих объектов на качество логистической регрессии при фиксированном наборе признаков и гиперпараметров модели (кроме `max_iter` в одном из запусков).  
**Гипотеза**: увеличение размера обучающей выборки приводит к росту качества (ROC-AUC, PR-AUC) до некоторого плато; при слишком малом числе итераций (`max_iter`) модель может недообучаться даже на большом датасете.

Используются следующие значения числа обучающих объектов `train_samples`: 500, 3000, 10000, 22792 (полный train), а также дополнительный запуск с `train_samples=22792` и увеличенным `max_iter=7000`.

### Таблица: зависимость метрик от размера выборки

| Run ID                               | Run name      | train_samples | max_iter | accuracy | roc_auc | PR-AUC (average_precision) | precision | recall | f1    |
|--------------------------------------|--------------|---------------|---------:|---------:|--------:|----------------------------:|----------:|-------:|------:|
| c408e9ed5af547069a924c37a680ed73     | Experiment #2 | 3000          | 1000     | 0.801    | 0.817   | 0.624                      | 0.676     | 0.326  | 0.440 |
| 939d49c44901494fbfa5c7474ee3b4e2     | Experiment #1 | 500           | 1000     | 0.785    | 0.805   | 0.602                      | 0.577     | 0.389  | 0.465 |
| e7a29b0a963a4ba785452c9278696989     | Experiment #3 | 10000         | 1000     | 0.802    | 0.814   | 0.617                      | 0.700     | 0.304  | 0.424 |
| ea6ea28d42f44cb895cb0bae2b9adbd4     | Experiment #4 | 22792         | 1000     | 0.802    | 0.813   | 0.618                      | 0.698     | 0.302  | 0.421 |
| 2d9a00962b5b4037b5b083f4c748914a     | Experiment #4b| 22792         | 7000     | 0.802    | 0.819   | 0.626                      | 0.687     | 0.315  | 0.432 |

График: зависимость ROC-AUC и PR-AUC от `train_samples` (график построен средствами MLflow UI).

### Выводы

- При увеличении числа обучающих примеров с 500 до 3000 наблюдается заметный рост ROC-AUC и PR-AUC, что подтверждает ожидаемую пользу от увеличения объёма данных.  
- При дальнейшем увеличении `train_samples` до 10000 и полного train (22792) метрики выходят на плато: выигрыши по ROC-AUC и PR-AUC становятся минимальными.  
- Дополнительный запуск с тем же максимальным размером выборки, но увеличенным `max_iter` с 1000 до 7000, показывает лёгкое улучшение ROC-AUC и PR-AUC, что указывает на важность достаточного числа итераций оптимизации при обучении логистической регрессии на полном датасете.

***

## Разрез 2. Коэффициент регуляризации C (логистическая регрессия)

### Описание и гипотеза

В этом разрезе исследуется влияние коэффициента регуляризации `C` в логистической регрессии на качество модели при фиксированных данных (размер выборки и набор признаков постоянны).  
**Гипотеза**: при слишком сильной регуляризации (малый `C`) модель недообучается, при слишком слабой (очень большой `C`) — может появляться переобучение, но в разумном диапазоне значений качество будет относительно стабильным.

Используемые значения параметра: `C ∈ {0.01, 0.1, 0.9, 3, 10}`.

### Таблица: зависимость метрик от C

| Run ID                               | Run name      | C    | accuracy | roc_auc | PR-AUC (average_precision) | precision | recall | f1    |
|--------------------------------------|--------------|------|---------:|--------:|----------------------------:|----------:|-------:|------:|
| 970eeaed13bd4d5db7be73ee1828a27d     | Experiment #5 | 0.01 | 0.802    | 0.819   | 0.625                      | 0.688     | 0.314  | 0.431 |
| fa558aa3d3ac4772a1b0028e63a023b3     | Experiment #6 | 0.1  | 0.801    | 0.819   | 0.626                      | 0.686     | 0.315  | 0.432 |
| 2d9a00962b5b4037b5b083f4c748914a     | Experiment #4b| 0.9  | 0.802    | 0.819   | 0.626                      | 0.687     | 0.315  | 0.432 |
| cb59d5af951245febdd8de1c03ecd475     | Experiment #7 | 3    | 0.801    | 0.819   | 0.626                      | 0.686     | 0.315  | 0.432 |
| 7c4eb7a09c2e47bc82228824f5c9fd1b     | Experiment #8 | 10   | 0.801    | 0.819   | 0.626                      | 0.686     | 0.315  | 0.432 |

График: зависимость ROC-AUC и PR-AUC от `C` (график построен средствами MLflow UI).

### Выводы

- В выбранном диапазоне значений `C` качества модели по ROC-AUC и PR-AUC практически не меняется: все запуски дают примерно одинаковые значения метрик.  
- Это показывает, что при текущем наборе признаков и размере выборки модель уже находится в «комфортной» зоне регуляризации, и изменение `C` в пределах [0.01, 10] не приводит к существенным улучшениям.  
- Небольшие колебания метрик можно объяснить флуктуациями оптимизации, а не систематическим эффектом параметра `C`.

***

## Разрез 3. Число признаков и состав фичей

### Описание и гипотеза

В этом разрезе исследуется влияние числа признаков и их состава на качество логистической регрессии при фиксированном размере обучающей выборки и одинаковых гиперпараметрах модели.  
**Гипотеза**: использование более информативных и разнообразных признаков должно приводить к росту ROC-AUC и PR-AUC; при слишком агрессивном сокращении числа фич модель теряет информацию и сильно деградирует.

Используются следующие варианты наборов признаков:

- 3 признака: `age, education, occupation`  
- 6 признаков: добавлены признаки о доходе и времени работы  
- 9 признаков: расширенный набор с демографическими признаками  
- 12 признаков: практически полный набор доступных фич

### Таблица: зависимость метрик от числа признаков

| Run ID                               | Run name      | n_features | features (кратко)                                      | accuracy | roc_auc | PR-AUC (average_precision) | precision | recall | f1    |
|--------------------------------------|--------------|-----------:|--------------------------------------------------------|---------:|--------:|----------------------------:|----------:|-------:|------:|
| f25a941f0e4644e6aebe312bd4bd1dbe     | Experiment #9 | 3          | age, education, occupation                            | 0.747    | 0.691   | 0.342                      | 0.295     | 0.040  | 0.071 |
| f5f8e9aa0e5b4d9f9b29e102909adbaf     | Experiment #10| 6          | + capital.gain, hours.per.week, marital.status        | 0.789    | 0.789   | 0.561                      | 0.665     | 0.242  | 0.355 |
| 9d4b773a89c943cfa6c4760e03736203     | Experiment #11| 9          | + race, relationship, sex                             | 0.793    | 0.810   | 0.603                      | 0.667     | 0.267  | 0.381 |
| e4b4e55210c046e3b8fab0b78b585c91     | Experiment #12| 12         | полный набор категориальных и числовых признаков      | 0.802    | 0.819   | 0.626                      | 0.687     | 0.315  | 0.432 |

График: зависимость ROC-AUC и PR-AUC от `n_features` (график построен средствами MLflow UI).

### Выводы

- Модель с очень малым числом признаков (3 фичи) показывает низкие значения всех метрик, особенно сильно падают PR-AUC и f1‑score, что свидетельствует о сильной потере информации.  
- Добавление информативных признаков (прежде всего признаков дохода и времени работы) приводит к заметному скачку ROC-AUC и PR-AUC, что подтверждает важность богатого признакового описания.  
- При дальнейшем увеличении числа признаков до почти полного набора ROC-AUC и PR-AUC продолжают монотонно расти, после чего качество выходит на уровень, сопоставимый с лучшими запусковыми настройками регуляризации.

***

## Разрез 4. Тип алгоритма и настройки логистической регрессии

### Описание и гипотеза

В этом разрезе сравниваются варианты настройки логистической регрессии по типу штрафа (`penalty`) и алгоритму оптимизации (`solver`) при фиксированных данных и коэффициенте регуляризации.  
**Гипотеза**: при разумных настройках solver’а и penalty качество (ROC-AUC и PR-AUC) будет сопоставимым, однако отдельные комбинации могут давать заметно хуже результат из‑за проблем с сходимостью или особенностей оптимизации.

### Таблица: метрики для разных penalty/solver

| Run ID                               | Run name      | penalty | solver    | accuracy | roc_auc | PR-AUC (average_precision) | precision | recall | f1    |
|--------------------------------------|--------------|---------|-----------|---------:|--------:|----------------------------:|----------:|-------:|------:|
| ad83f819fda44afbacf3483ab0bc9d72     | Experiment #13| l2      | lbfgs     | 0.802    | 0.819   | 0.626                      | 0.687     | 0.315  | 0.432 |
| 826086ba234e40f188997b83c5cb7af7     | Experiment #14| l1      | liblinear | 0.801    | 0.819   | 0.626                      | 0.691     | 0.309  | 0.427 |
| 1761d165386843a9b3e4601cd51dab93     | Experiment #15| l1      | saga      | 0.807    | 0.499   | 0.445                      | 0.763     | 0.283  | 0.413 |

График: сравнение ROC-AUC и PR-AUC для различных комбинаций `penalty` и `solver`.

### Выводы

- Комбинации `l2 + lbfgs` и `l1 + liblinear` дают очень близкие значения ROC-AUC и PR-AUC, что говорит о том, что при текущем наборе фич и данных выбор типа штрафа менее критичен, чем, например, число признаков.  
- Настройка `l1 + saga` демонстрирует заметное падение ROC-AUC и PR-AUC при внешне неплохих значениях accuracy, что указывает на проблемы именно с ранжированием вероятностей и качеством работы на миноритарном классе.  
- В контексте этой задачи более устойчивыми оказались классические связки `lbfgs/l2` и `liblinear/l1`, поэтому для итогового сравнения и дальнейших экспериментов использовались именно они.

***

## CatBoost + Optuna (подбор гиперпараметров)

### Описание и гипотеза

В этом блоке исследуется влияние гиперпараметров CatBoost на качество бинарной классификации с целевой метрикой ROC-AUC, а подбор выполняется через Optuna (фиксируется датасет и пайплайн подготовки данных, меняются только параметры модели). [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)
Гипотеза: градиентный бустинг по деревьям при корректной настройке способен существенно улучшить ROC-AUC и PR-AUC по сравнению с линейной моделью за счёт учёта нелинейностей и взаимодействий признаков. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)

### Лучший запуск (Optuna best)

Ссылка на лучший запуск по ROC-AUC: http://158.160.2.37:5000/#/experiments/9/runs/c6a14f325f9b4caa8435e89b8a2fbb0d [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)

Параметры лучшей конфигурации CatBoost: `iterations=400`, `learning_rate=0.09714828622959232`, `border_count=116`, `depth=6`, `l2_leaf_reg=0.643564818580567`. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)

### Метрики лучшего запуска

| Run ID | model_type | best_roc_auc | best_average_precision (PR-AUC) | best_accuracy | best_precision | best_recall | best_f1 | n_trials |
|---|---|---:|---:|---:|---:|---:|---:|---:|
| c6a14f325f9b4caa8435e89b8a2fbb0d | CatBoost | 0.9301221650 | 0.8288617254 | 0.8733749616 | 0.7856033143 | 0.6482905983 | 0.7103722782 | 50 |

Графики/таблицы зависимости метрик от параметров (Optuna trials) получены в MLflow UI для данного эксперимента и используются для анализа влияния `depth`, `learning_rate`, `l2_leaf_reg` и `iterations` на ROC-AUC/PR-AUC. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)

### Выводы

Лучший запуск CatBoost после Optuna-подбора достиг ROC-AUC = 0.9301 и PR-AUC = 0.8289, что делает его итоговым кандидатом на финальную модель в рамках задания (выбор по максимальному ROC-AUC). [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)
Модель залогирована в MLflow как отдельная сущность (logged model) и доступна в артефактах run’а. [ppl-ai-file-upload.s3.amazonaws](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/94268956/4991030c-ca21-45a5-b118-d49c1996e21c/runner.py)
