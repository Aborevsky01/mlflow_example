# Отчёт по анализу экспериментов Mavletova

## Общая информация

Всего проведено **12 экспериментов**, которые группируются в три разреза:

- **Разрез A**: размер обучающей выборки (4 эксперимента)
- **Разрез B**: тип модели (4 эксперимента)
- **Разрез C**: тип solver в логистической регрессии (4 эксперимента)

Во всех экспериментах использовался фиксированный набор из **7 признаков**: `race`, `sex`, `native.country`, `hours.per.week`, `occupation`, `marital.status`, `education`.

***

## Разрез A. Размер обучающей выборки

### Описание и гипотеза

В данном разрезе исследуется влияние количества обучающих объектов на качество логистической регрессии при фиксированном наборе признаков и гиперпараметров модели (`max_iter=500`, `solver=lbfgs`, `C=1`).

**Гипотеза**: увеличение размера обучающей выборки должно приводить к росту качества модели (ROC-AUC, PR-AUC) за счёт лучшего обучения на большем объёме данных.

Используемые значения `train_size`: 1000, 6000, 15000, 20000.

### Таблица: зависимость метрик от размера выборки

| Run ID | Run name | train_size | model_type | accuracy | roc_auc | pr_auc | precision | recall | f1_score |
|--------|----------|------------|------------|----------|---------|--------|-----------|--------|----------|
| 2157e084e2e1415a95e6fa33ba98bd75 | A_train_size_1000 | 1000 | logreg | 0.755 | 0.745 | 0.416 | 0.464 | 0.137 | 0.211 |
| 9d9583c582554472ae0a6e97e735cc6d | A_train_size_6000 | 6000 | logreg | 0.752 | 0.748 | 0.418 | 0.407 | 0.074 | 0.125 |
| fdd2f807bbd041f1813d736fdd1d55f9 | A_train_size_15000 | 15000 | logreg | 0.752 | 0.749 | 0.417 | 0.417 | 0.087 | 0.144 |
| fa995c0ef17d471089f48a39c0027ef2 | A_train_size_20000 | 20000 | logreg | 0.751 | 0.749 | 0.417 | 0.406 | 0.082 | 0.136 |

График: зависимость ROC-AUC от `train_size`.

![Axis 0](img/axis_mavletova_0.png)

### Выводы

Результаты данного разреза показывают **неожиданный эффект**: при увеличении размера обучающей выборки ROC-AUC практически не меняется и остаётся на уровне 0.745–0.749, что противоречит исходной гипотезе.

При этом наблюдается интересная динамика в метриках классификации:
- Наибольший f1-score (0.211) и recall (0.137) достигнуты на **минимальной выборке** (1000 объектов), что может указывать на случайную удачную балансировку классов или специфику разбиения.
- При увеличении размера выборки recall и f1 снижаются, хотя precision остаётся относительно стабильным.

Такое поведение может объясняться:
- **Недостаточностью выбранных 7 признаков** для выделения закономерностей на большей выборке;
- **Сильной регуляризацией** (C=1 для данной задачи может быть избыточным);
- **Особенностями разбиения train/test**, при которых малая выборка случайно оказалась более репрезентативной.

В целом, данный разрез не подтверждает гипотезу о росте ROC-AUC с увеличением размера выборки при фиксированном малом наборе признаков.

***

## Разрез B. Тип модели

### Описание и гипотеза

В этом разрезе сравниваются различные алгоритмы машинного обучения на одной и той же обучающей выборке (размер не указан явно, но фиксирован для всех запусков) и одном наборе из 7 признаков.

**Гипотеза**: более сложные модели (деревья решений, случайный лес, градиентный бустинг) должны показывать существенно лучшее качество по сравнению с линейной логистической регрессией благодаря способности улавливать нелинейные зависимости.

Сравниваемые модели:
- Логистическая регрессия (`logreg`)
- Дерево решений (`decision_tree`)
- Случайный лес (`random_forest`)
- Градиентный бустинг (`gradient_boosting`)

### Таблица: сравнение моделей

| Run ID | Run name | model_type | model_params | accuracy | roc_auc | pr_auc | precision | recall | f1_score |
|--------|----------|------------|--------------|----------|---------|--------|-----------|--------|----------|
| 4ff440ea66274be1af31fb3fd223c571 | B_model_type_logreg | logreg | max_iter=500, solver=lbfgs, C=1 | 0.752 | 0.748 | 0.416 | 0.402 | 0.076 | 0.129 |
| b2a875b80821415eb89092438b05dd41 | B_model_type_decisiontree | decision_tree | max_depth=8, min_samples_split=10 | 0.818 | 0.862 | 0.632 | 0.670 | 0.474 | 0.555 |
| b8fe0a0351fb4c1bbf885937998bd4f1 | B_model_type_randomforest | random_forest | n_estimators=300, max_depth=12, min_samples_split=10 | 0.825 | 0.876 | 0.678 | 0.683 | 0.506 | 0.581 |
| bcbcc5a8281848fbb0b3bb3a56eb0396 | B_model_type_gradientboosting | gradient_boosting | n_estimators=300, learning_rate=0.05, max_depth=3 | 0.828 | 0.880 | 0.687 | 0.696 | 0.501 | 0.582 |

График: сравнение ROC-AUC для различных типов моделей.

![Axis 1](img/axis_mavletova_1.png)

### Выводы

Гипотеза **полностью подтверждается**: древовидные модели демонстрируют значительное превосходство над линейной логистической регрессией:

- **Градиентный бустинг** показывает лучшие результаты по ROC-AUC (0.880) и PR-AUC (0.687), что на **~18% выше** по ROC-AUC и на **~65% выше** по PR-AUC по сравнению с логистической регрессией.
- **Случайный лес** занимает второе место с ROC-AUC = 0.876, показывая сопоставимое с градиентным бустингом качество.
- **Дерево решений** уже даёт заметное улучшение (ROC-AUC = 0.862) по сравнению с логрегом, но уступает ансамблевым методам.

Важно отметить кратный рост recall (с 0.076 у логрега до 0.501–0.506 у ансамблевых моделей), что критично для задачи бинарной классификации с несбалансированными классами.

Результаты показывают, что при ограниченном наборе признаков (7 фич) способность древовидных моделей извлекать нелинейные взаимодействия между признаками критически важна для достижения высокого качества.

***

## Разрез C. Тип solver в логистической регрессии

### Описание и гипотеза

В этом разрезе исследуется влияние выбора алгоритма оптимизации (`solver`) в логистической регрессии при фиксированных данных и остальных гиперпараметрах (`max_iter=500`, `C=1`).

**Гипотеза**: при достаточном числе итераций и корректных настройках все solver'ы должны давать примерно одинаковое качество (ROC-AUC, PR-AUC), поскольку решают одну и ту же задачу выпуклой оптимизации.

Сравниваемые solver'ы:
- `lbfgs` (квази-ньютоновский метод, по умолчанию)
- `liblinear` (координатный спуск, подходит для малых датасетов)
- `saga` (стохастический градиентный спуск)
- `sag` (стохастический градиентный спуск без усреднения)

### Таблица: зависимость метрик от solver

| Run ID | Run name | solver | accuracy | roc_auc | pr_auc | precision | recall | f1_score |
|--------|----------|--------|----------|---------|--------|-----------|--------|----------|
| 1204c49fb38e4db38d18b70fb4d5cc60 | C_logreg_solver_type_lbfgs | lbfgs | 0.752 | 0.749 | 0.417 | 0.417 | 0.087 | 0.144 |
| a0ea27d781744fdc96dc65853f92965f | C_logreg_solver_type_liblinear | liblinear | 0.752 | 0.749 | 0.417 | 0.412 | 0.084 | 0.140 |
| 314c907588eb4de98aef96655a8b2689 | C_logreg_solver_type_saga | saga | 0.751 | 0.749 | 0.417 | 0.404 | 0.080 | 0.134 |
| d350217a5ce844148f511ca2777c5a1f | C_logreg_solver_type_sag | sag | 0.751 | 0.749 | 0.417 | 0.407 | 0.084 | 0.139 |

График нет возможности построить из-за особенностей логгирования

### Выводы

Гипотеза **подтверждается**: все четыре solver'а демонстрируют практически идентичные значения ключевых метрик:
- ROC-AUC стабилен на уровне 0.749 для всех экспериментов
- PR-AUC также одинаков (0.417) во всех запусках
- Незначительные различия в precision, recall и f1-score (в пределах 2–3%) можно объяснить флуктуациями численной оптимизации

Это подтверждает, что при текущих настройках (`max_iter=500`) все алгоритмы успевают сойтись к одному и тому же оптимуму задачи логистической регрессии.

Вывод: для данной задачи и датасета **выбор solver не является критическим фактором** при условии достаточного числа итераций. Можно использовать дефолтный `lbfgs` без потери качества.

***

## Итоговое сравнение и лучший запуск

### Лучший запуск по ROC-AUC

Ссылка на лучший запуск: [bcbcc5a8281848fbb0b3bb3a56eb0396](http://158.160.2.37:5000/#/experiments/15/runs/bcbcc5a8281848fbb0b3bb3a56eb0396)

**Параметры:**
- Model type: Gradient Boosting
- Parameters: `n_estimators=300`, `learning_rate=0.05`, `max_depth=3`
- Features: 7 признаков (race, sex, native.country, hours.per.week, occupation, marital.status, education)

**Метрики:**
- ROC-AUC: **0.880**
- PR-AUC: **0.687**
- Accuracy: **0.828**
- Precision: **0.696**
- Recall: **0.501**
- F1-score: **0.582**

### Общие выводы по экспериментам

1. **Выбор модели — ключевой фактор качества**: переход от логистической регрессии к градиентному бустингу даёт прирост ROC-AUC на ~18%, что значительно превосходит эффекты от изменения размера выборки или настроек оптимизации.

2. **Ограниченный набор признаков**: использование всего 7 признаков накладывает потолок на качество линейной модели (ROC-AUC ~0.75), но древовидные модели способны лучше извлекать взаимодействия из этого малого набора.

3. **Размер выборки не критичен при малом числе признаков**: в диапазоне 1000–20000 объектов качество логистической регрессии практически не меняется, что может указывать на необходимость расширения признакового пространства для дальнейшего улучшения.

4. **Технические настройки (solver) не критичны**: при достаточном числе итераций все solver'ы логистической регрессии дают идентичное качество.
